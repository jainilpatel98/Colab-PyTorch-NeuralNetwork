{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_VARIABLE = \"isPA\"\n",
    "\n",
    "# possibilities for the target variables are \n",
    "# isPA, isRPO, off_form, rec_form, playType, passCov, runConcept, off_scs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "\n",
    "class CNN_Transformer_Model(nn.Module):\n",
    "    def __init__(self, input_size=9216, d_model=512, nhead=8, num_layers=2, \n",
    "                 dim_feedforward=2048, num_classes=2, dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        # CNN feature extractor (same as before)\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            \n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            \n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        \n",
    "        # Transformer components\n",
    "        self.feature_projection = nn.Linear(input_size, d_model)\n",
    "        self.positional_encoding = PositionalEncoding(d_model, dropout)\n",
    "        encoder_layers = TransformerEncoderLayer(d_model, nhead, dim_feedforward, \n",
    "                                                dropout, batch_first=True)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, num_layers)\n",
    "        self.fc = nn.Linear(d_model, num_classes)\n",
    "\n",
    "    def forward(self, x, src_key_padding_mask=None):\n",
    "        batch_size, seq_len, channels, height, width = x.size()\n",
    "        cnn_features = []\n",
    "        \n",
    "        # Process each frame through CNN\n",
    "        for i in range(seq_len):\n",
    "            frame_features = self.cnn(x[:, i]).flatten(1)\n",
    "            cnn_features.append(frame_features)\n",
    "            \n",
    "        cnn_features = torch.stack(cnn_features, dim=1)\n",
    "        projected_features = self.feature_projection(cnn_features)\n",
    "        transformer_input = self.positional_encoding(projected_features)\n",
    "        \n",
    "        # Transformer with mask\n",
    "        transformer_output = self.transformer_encoder(\n",
    "            transformer_input, \n",
    "            src_key_padding_mask=src_key_padding_mask\n",
    "        )\n",
    "        \n",
    "        pooled_output = transformer_output.mean(dim=1)\n",
    "        return self.fc(pooled_output)\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        # Corrected positional encoding calculation\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        \n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = x + self.pe[:x.size(1)]  # Add positional encoding to sequence\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class SequentialImageDataset(Dataset):\n",
    "    def __init__(self, image_pickle, label_pickle, transform=None):\n",
    "        self.transform = transform\n",
    "\n",
    "        self.frames = pd.read_pickle(image_pickle)\n",
    "        self.labels = pd.read_pickle(label_pickle)\n",
    "        self.game_plays = np.unique(self.labels['game_play'])\n",
    "        self.encoded_labels = self.labels.groupby('game_play')[TARGET_VARIABLE].first().to_dict()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.game_plays)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        gp = self.game_plays[idx]\n",
    "        gp_frames = self.frames[self.frames['game_play'] == gp]\n",
    "\n",
    "        sequence = []\n",
    "        frame_nums = sorted(gp_frames['frameId'].unique())\n",
    "\n",
    "        for frame_num in frame_nums:\n",
    "            frame_data = gp_frames[gp_frames['frameId'] == frame_num]\n",
    "            frame_matrix = np.zeros((100, 100), dtype='float32')\n",
    "\n",
    "            for _, row in frame_data.iterrows():\n",
    "                x, y, val = int(row['col_norm']), int(row['row_idx']), row['pos_id']\n",
    "                if 0 <= x < 100 and 0 <= y < 100:\n",
    "                    frame_matrix[y, x] = val\n",
    "\n",
    "            if self.transform:\n",
    "                frame_matrix = self.transform(frame_matrix)\n",
    "            sequence.append(frame_matrix)\n",
    "\n",
    "        sequence = np.array(sequence)\n",
    "        sequence = np.expand_dims(sequence, axis=1)  # Shape: [seq_length, channels, H, W]\n",
    "        \n",
    "        label = self.encoded_labels[gp]\n",
    "\n",
    "        # label_pa = self.labels[self.labels['game_play'] == gp][TARGET_VARIABLE].iloc[0]\n",
    "        return torch.tensor(sequence), torch.tensor(label, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset and DataLoader\n",
    "image_train = './splits/tracking_processed_train.pkl'\n",
    "label_train = './splits/label_processed_train.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import joblib  # Install with `pip install joblib`\n",
    "from sklearn.utils import resample\n",
    "\n",
    "\n",
    "# Load and encode labels BEFORE creating dataset\n",
    "raw_labels = pd.read_pickle(label_train)\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Create mapping: game_play -> encoded label\n",
    "encoded_labels = raw_labels.groupby('game_play')[TARGET_VARIABLE].first()\n",
    "encoded_labels = label_encoder.fit_transform(encoded_labels)\n",
    "\n",
    "# Create label mapping dictionary\n",
    "label_mapping = dict(zip(raw_labels['game_play'].unique(), encoded_labels))\n",
    "\n",
    "# Create dataset with encoded labels\n",
    "dataset_train = SequentialImageDataset(\n",
    "    image_pickle=image_train,\n",
    "    label_pickle=label_train,\n",
    "    transform=None\n",
    ")\n",
    "\n",
    "# Inject the pre-encoded labels\n",
    "dataset_train.encoded_labels = label_mapping\n",
    "\n",
    "# Save encoder\n",
    "joblib.dump(label_encoder, f'label_encoder_{TARGET_VARIABLE}.pkl')\n",
    "\n",
    "\n",
    "# Count class occurrences\n",
    "import numpy as np\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Get true class distribution from the dataset's encoded_labels\n",
    "game_plays = dataset_train.game_plays  # Sorted unique game_plays\n",
    "true_labels = np.array([dataset_train.encoded_labels[gp] for gp in game_plays])\n",
    "\n",
    "# Calculate class counts and max count\n",
    "unique_classes, class_counts = np.unique(true_labels, return_counts=True)\n",
    "max_count = np.max(class_counts)\n",
    "\n",
    "# Create balanced indices aligned with game_plays order\n",
    "balanced_indices = []\n",
    "for cls in unique_classes:\n",
    "    # Get indices in game_plays order where class == cls\n",
    "    cls_mask = (true_labels == cls)\n",
    "    cls_indices = np.where(cls_mask)[0]\n",
    "    \n",
    "    # Resample to max_count\n",
    "    resampled = resample(cls_indices,\n",
    "                         replace=True,\n",
    "                         n_samples=max_count,\n",
    "                         random_state=42)\n",
    "    balanced_indices.extend(resampled)\n",
    "\n",
    "balanced_subset = torch.utils.data.Subset(dataset_train, balanced_indices)\n",
    "\n",
    "\n",
    "# Custom collate function to pad sequences to the same length\n",
    "def collate_fn(batch):\n",
    "    sequences, labels = zip(*batch)\n",
    "    lengths = [seq.shape[0] for seq in sequences]\n",
    "    max_length = max(lengths)\n",
    "    \n",
    "    # Initialize padded tensor and mask\n",
    "    padded_sequences = torch.zeros(len(sequences), max_length, *sequences[0].shape[1:])\n",
    "    src_key_padding_mask = torch.zeros(len(sequences), max_length, dtype=torch.bool)\n",
    "    \n",
    "    for i, seq in enumerate(sequences):\n",
    "        seq_length = lengths[i]\n",
    "        padded_sequences[i, :seq_length] = seq\n",
    "        if seq_length < max_length:\n",
    "            src_key_padding_mask[i, seq_length:] = True  # Mask padding positions\n",
    "            \n",
    "    return padded_sequences, torch.stack(labels), src_key_padding_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Balanced Subset Verification (isPA)\n",
      "==================================================\n",
      "Total samples: 21332\n",
      "Number of classes: 2\n",
      "\n",
      "Class               Count     Percentage     Deviation from Ideal\n",
      "0                   10666     50.00%               +0.0 (+0.0%)\n",
      "1                   10666     50.00%               +0.0 (+0.0%)\n",
      "\n",
      "Quality Metrics:\n",
      "Max-Min Ratio: 1.00:1\n",
      "Standard Deviation: 0.0\n",
      "Coefficient of Variation: 0.0%\n",
      "Ideal Count: 10666.0\n",
      "\n",
      "Statistical Test:\n",
      "Chi-squared p-value: 1.0000 (Balanced)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Index Integrity Checks:\n",
      "Unique indices: 8867/21332\n",
      "Max index: 12845 (Dataset size: 12847)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "# Get actual labels from the balanced subset\n",
    "subset_labels = [balanced_subset.dataset.encoded_labels[balanced_subset.dataset.game_plays[idx]] \n",
    "                for idx in balanced_subset.indices]\n",
    "\n",
    "# Convert to class names using label encoder\n",
    "class_names = label_encoder.classes_\n",
    "subset_class_names = label_encoder.inverse_transform(subset_labels)\n",
    "\n",
    "# 1. Class Distribution Analysis\n",
    "class_counts = Counter(subset_class_names)\n",
    "total_samples = len(balanced_subset)\n",
    "num_classes = len(class_counts)\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(f\"Balanced Subset Verification ({TARGET_VARIABLE})\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Total samples: {total_samples}\")\n",
    "print(f\"Number of classes: {num_classes}\\n\")\n",
    "\n",
    "# Print class distribution with multiple metrics\n",
    "print(f\"{'Class':<20}{'Count':<10}{'Percentage':<15}{'Deviation from Ideal':<20}\")\n",
    "ideal_count = total_samples / num_classes\n",
    "for cls, count in class_counts.items():\n",
    "    deviation = count - ideal_count\n",
    "    print(f\"{cls:<20}{count:<10}{count/total_samples:<15.2%}{deviation:>+10.1f} ({deviation/ideal_count:+.1%})\")\n",
    "\n",
    "# 2. Statistical Validation\n",
    "count_values = np.array(list(class_counts.values()))\n",
    "max_count = count_values.max()\n",
    "min_count = count_values.min()\n",
    "std_dev = count_values.std()\n",
    "cov = std_dev / count_values.mean()\n",
    "\n",
    "print(\"\\nQuality Metrics:\")\n",
    "print(f\"Max-Min Ratio: {max_count/min_count:.2f}:1\")\n",
    "print(f\"Standard Deviation: {std_dev:.1f}\")\n",
    "print(f\"Coefficient of Variation: {cov:.1%}\")\n",
    "print(f\"Ideal Count: {ideal_count:.1f}\")\n",
    "\n",
    "# 3. Chi-Squared Test for Uniformity\n",
    "from scipy.stats import chisquare\n",
    "chi2, p_value = chisquare(count_values)\n",
    "print(f\"\\nStatistical Test:\")\n",
    "print(f\"Chi-squared p-value: {p_value:.4f} ({'Balanced' if p_value > 0.05 else 'Imbalanced'})\")\n",
    "\n",
    "# 4. Visual Verification\n",
    "plt.figure(figsize=(12, 6))\n",
    "bars = plt.bar(class_names, count_values)\n",
    "plt.axhline(ideal_count, color='r', linestyle='--', label=f'Ideal ({ideal_count:.1f})')\n",
    "plt.title(f\"Class Distribution in Balanced Subset\\n({TARGET_VARIABLE}, p={p_value:.3f})\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "\n",
    "# Add value labels with percentage deviation\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    deviation = (height - ideal_count)/ideal_count\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f\"{height}\\n({deviation:+.1%})\",\n",
    "             ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 5. Index Sanity Checks\n",
    "print(\"\\nIndex Integrity Checks:\")\n",
    "# Check for duplicate indices\n",
    "unique_indices = len(np.unique(balanced_subset.indices))\n",
    "print(f\"Unique indices: {unique_indices}/{len(balanced_subset.indices)}\")\n",
    "\n",
    "# Validate index range\n",
    "max_index = max(balanced_subset.indices)\n",
    "print(f\"Max index: {max_index} (Dataset size: {len(balanced_subset.dataset)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution plot saved as class_distribution_isPA.png\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_class_distribution(original_counts, balanced_counts, filename=f'class_distribution_{TARGET_VARIABLE}.png'):\n",
    "    classes = list(original_counts.keys())\n",
    "    x = np.arange(len(classes))\n",
    "    width = 0.35\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    # Original distribution\n",
    "    rects1 = ax.bar(x - width/2, [original_counts[c] for c in classes], \n",
    "                   width, label='Original', color='skyblue')\n",
    "    # Balanced distribution\n",
    "    rects2 = ax.bar(x + width/2, [balanced_counts[c] for c in classes], \n",
    "                   width, label='Balanced', color='salmon')\n",
    "\n",
    "    ax.set_xlabel('Class')\n",
    "    ax.set_ylabel('Number of Samples')\n",
    "    ax.set_title(f'Class Distribution Before and After Balancing {TARGET_VARIABLE}')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(classes)\n",
    "    ax.legend()\n",
    "\n",
    "    # Add exact counts on top of bars\n",
    "    for rect in rects1 + rects2:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate(f'{height}',\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# Get balanced labels\n",
    "balanced_labels = encoded_labels[balanced_indices]\n",
    "\n",
    "# Count classes in balanced subset\n",
    "balanced_counts = Counter(balanced_labels)\n",
    "\n",
    "# Create and save plot\n",
    "plot_class_distribution(class_counts, balanced_counts)\n",
    "\n",
    "print(f\"Class distribution plot saved as class_distribution_{TARGET_VARIABLE}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "Number of GPUs: 4\n",
      "Number of classes: 2\n",
      "Using 4 GPUs with DataParallel!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:   0%|          | 0/4267 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  35%|███▍      | 1483/4267 [13:14<24:51,  1.87it/s, loss=0.72] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 105\u001b[0m\n\u001b[1;32m    103\u001b[0m mask \u001b[38;5;241m=\u001b[39m padding_mask\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    104\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 105\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m    108\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/.conda/envs/myenv/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/myenv/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.conda/envs/myenv/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py:193\u001b[0m, in \u001b[0;36mDataParallel.forward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule(\u001b[38;5;241m*\u001b[39minputs[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodule_kwargs[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    192\u001b[0m replicas \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplicate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_ids[: \u001b[38;5;28mlen\u001b[39m(inputs)])\n\u001b[0;32m--> 193\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparallel_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgather(outputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_device)\n",
      "File \u001b[0;32m~/.conda/envs/myenv/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py:212\u001b[0m, in \u001b[0;36mDataParallel.parallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparallel_apply\u001b[39m(\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;28mself\u001b[39m, replicas: Sequence[T], inputs: Sequence[Any], kwargs: Any\n\u001b[1;32m    211\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Any]:\n\u001b[0;32m--> 212\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparallel_apply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/myenv/lib/python3.9/site-packages/torch/nn/parallel/parallel_apply.py:118\u001b[0m, in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m    116\u001b[0m         thread\u001b[38;5;241m.\u001b[39mstart()\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m thread \u001b[38;5;129;01min\u001b[39;00m threads:\n\u001b[0;32m--> 118\u001b[0m         \u001b[43mthread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    120\u001b[0m     _worker(\u001b[38;5;241m0\u001b[39m, modules[\u001b[38;5;241m0\u001b[39m], inputs[\u001b[38;5;241m0\u001b[39m], kwargs_tup[\u001b[38;5;241m0\u001b[39m], devices[\u001b[38;5;241m0\u001b[39m], streams[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/.conda/envs/myenv/lib/python3.9/threading.py:1060\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1057\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1059\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1060\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1062\u001b[0m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   1063\u001b[0m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m   1064\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[0;32m~/.conda/envs/myenv/lib/python3.9/threading.py:1080\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1077\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1079\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1080\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1081\u001b[0m         lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m   1082\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# Assume the model and dataset are defined/imported from previous cells\n",
    "# from model import CNN_LSTM_PA_Model\n",
    "# from dataset import SequentialImageDataset\n",
    "\n",
    "# Checkpoint directory\n",
    "CHECKPOINT_DIR = \"checkpoints\"\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "def checkpoint(model, optimizer, filename):\n",
    "    torch.save({\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "        'model': model.state_dict(),\n",
    "    }, os.path.join(CHECKPOINT_DIR, filename))\n",
    "\n",
    "def model_resume(model, optimizer, filename):\n",
    "    ckpt = torch.load(os.path.join(CHECKPOINT_DIR, filename))\n",
    "    model.load_state_dict(ckpt['model'])\n",
    "    optimizer.load_state_dict(ckpt['optimizer'])\n",
    "\n",
    "# Check CUDA availability first\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "labels = encoded_labels\n",
    "\n",
    "# Get number of classes dynamically\n",
    "num_classes = len(np.unique(labels))\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "\n",
    "# Model initialization\n",
    "model = CNN_Transformer_Model(\n",
    "    input_size=9216,        # Must match CNN output features (64*12*12=9216)\n",
    "    d_model=512,            # Transformer dimension\n",
    "    nhead=8,                # Number of attention heads\n",
    "    num_layers=2,           # Number of transformer layers\n",
    "    dim_feedforward=2048,   # Feedforward dimension\n",
    "    num_classes=num_classes,             # Number of classes\n",
    "    dropout=0.1\n",
    ")\n",
    "\n",
    "# Multi-GPU setup\n",
    "if torch.cuda.is_available():\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(f\"Using {torch.cuda.device_count()} GPUs with DataParallel!\")\n",
    "        model = nn.DataParallel(model)\n",
    "    # Move model to device AFTER DataParallel wrapping\n",
    "    model = model.to(device)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "else:\n",
    "    print(\"Warning: Training on CPU - CUDA not available\")\n",
    "    \n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Use the existing train_loader that has the custom collate function\n",
    "# Remove the incorrect DataLoader redefinition:\n",
    "\n",
    "# First create the balanced subset\n",
    "\n",
    "\n",
    "# Then create the DataLoader with both balancing and proper collate\n",
    "train_loader = DataLoader(\n",
    "    balanced_subset,\n",
    "    batch_size=5,  # Increased from 1\n",
    "    shuffle=True,\n",
    "    num_workers=128,  # Reduced from 64\n",
    "    persistent_workers=True,\n",
    "    pin_memory=True,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "# Remove any other DataLoader definitions (e.g., this one):\n",
    "\n",
    "# Training parameters\n",
    "num_epochs = 10\n",
    "loss_history = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    \n",
    "    for padded_sequences, labels, padding_mask in pbar:\n",
    "        inputs = padded_sequences.to(device)\n",
    "        \n",
    "        labels = labels.to(device)\n",
    "        mask = padding_mask.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs, src_key_padding_mask=mask)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        pbar.set_postfix(loss=running_loss / (pbar.n + 1))\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    loss_history.append(epoch_loss)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] - Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    checkpoint(model, optimizer, f'epoch-{epoch}.pth')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 12\u001b[0m\n\u001b[1;32m      1\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader(\n\u001b[1;32m      2\u001b[0m     balanced_subset,\n\u001b[1;32m      3\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,  \u001b[38;5;66;03m# Increased from 1\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m     collate_fn\u001b[38;5;241m=\u001b[39mcollate_fn\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[0;32m---> 12\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m \u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m():\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(\n",
    "    balanced_subset,\n",
    "    batch_size=5,  # Increased from 1\n",
    "    shuffle=True,\n",
    "    num_workers=1,  # Reduced from 64\n",
    "    persistent_workers=True,\n",
    "    pin_memory=True,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]]]]), tensor([0, 1, 1, 0, 0]), tensor([[False, False, False,  ...,  True,  True,  True],\n",
      "        [False, False, False,  ...,  True,  True,  True],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ...,  True,  True,  True],\n",
      "        [False, False, False,  ...,  True,  True,  True]])]\n"
     ]
    }
   ],
   "source": [
    "for batch in train_loader:\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 201, 1, 100, 100])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False,  ...,  True,  True,  True],\n",
       "        [False, False, False,  ...,  True,  True,  True],\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ...,  True,  True,  True],\n",
       "        [False, False, False,  ...,  True,  True,  True]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during plotting: x and y must have same first dimension, but have shapes (10,) and (0,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Save final model\n",
    "torch.save(model.state_dict(), f'CNN_TRANSFORMER_{TARGET_VARIABLE}_final.pth')\n",
    "\n",
    "# Plot and save training loss\n",
    "try:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(1, num_epochs + 1), loss_history, marker='o', linestyle='-', color='b')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title(f'Training Loss for Play Action ({TARGET_VARIABLE})) Prediction')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the plot\n",
    "    plt.savefig(f'training_loss_{TARGET_VARIABLE}.png', dpi=300, bbox_inches='tight')  # Save as high-res PNG\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print(f\"Error during plotting: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12922/4222637066.py:51: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(f'CNN_TRANSFORMER_{TARGET_VARIABLE}_final.pth'))\n",
      "Evaluating:   0%|          | 0/101 [00:00<?, ?it/s]/home/japmyy/.conda/envs/myenv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:502: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. (Triggered internally at /opt/conda/conda-bld/pytorch_1729647380992/work/aten/src/ATen/NestedTensorImpl.cpp:178.)\n",
      "  output = torch._nested_tensor_from_mask(\n",
      "Evaluating: 100%|██████████| 101/101 [06:15<00:00,  3.72s/it]\n"
     ]
    }
   ],
   "source": [
    "# First create test dataset and loader\n",
    "image_test = './splits/tracking_processed_test.pkl'\n",
    "label_test = './splits/label_processed_test.pkl'\n",
    "\n",
    "# Load encoder\n",
    "label_encoder = joblib.load(f'label_encoder_{TARGET_VARIABLE}.pkl')\n",
    "\n",
    "# Prepare test dataset with encoded labels\n",
    "raw_test_labels = pd.read_pickle(label_test)\n",
    "test_game_plays = raw_test_labels['game_play'].unique()\n",
    "encoded_test_labels = label_encoder.transform(\n",
    "    raw_test_labels.groupby('game_play')[TARGET_VARIABLE].first()\n",
    ")\n",
    "\n",
    "dataset_test = SequentialImageDataset(\n",
    "    image_pickle=image_test,\n",
    "    label_pickle=label_test,\n",
    "    transform=None\n",
    ")\n",
    "dataset_test.encoded_labels = dict(zip(test_game_plays, encoded_test_labels))\n",
    "\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset_test,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "def evaluate_model(model, loader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for padded_sequences, labels, padding_mask in tqdm(loader, desc=\"Evaluating\"):\n",
    "            inputs = padded_sequences.to(device)\n",
    "            labels = labels.to(device)\n",
    "            mask = padding_mask.to(device)\n",
    "            \n",
    "            outputs = model(inputs, src_key_padding_mask=mask)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    return all_labels, all_preds\n",
    "\n",
    "# Load best model (using final model in this case)\n",
    "model.load_state_dict(torch.load(f'CNN_TRANSFORMER_{TARGET_VARIABLE}_final.pth'))\n",
    "model = model.to(device)\n",
    "\n",
    "# Run evaluation\n",
    "true_labels, predictions = evaluate_model(model, test_loader, device)\n",
    "\n",
    "# Metrics and visualization\n",
    "from sklearn.metrics import (confusion_matrix, accuracy_score, \n",
    "                             classification_report, ConfusionMatrixDisplay)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Confusion Matrix\n",
    "def plot_confusion_matrix(y_true, y_pred, classes, filename):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(8,6))\n",
    "    disp.plot(ax=ax, cmap=plt.cm.Blues)\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# Metrics Summary\n",
    "def plot_metrics_summary(y_true, y_pred, filename):\n",
    "    report = classification_report(y_true, y_pred, output_dict=True)\n",
    "    \n",
    "    metrics = ['precision', 'recall', 'f1-score']\n",
    "    classes = list(report.keys())[:-3]  # Exclude avg/total\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for cls in classes:\n",
    "        values = [report[cls][metric] for metric in metrics]\n",
    "        plt.plot(metrics, values, marker='o', label=cls)\n",
    "    \n",
    "    plt.title(\"Classification Metrics\")\n",
    "    plt.ylim(0, 1.1)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation completed. Saved:\n",
      "- confusion_matrixisPA.png\n",
      "- classification_metrics{TARGET_VARIABLE}.png\n",
      "- test_metrics.txt\n"
     ]
    }
   ],
   "source": [
    "# Generate and save plots\n",
    "# class_names = ['Non-PA', 'PA']  # Update with your actual class names\n",
    "class_names = [str(cls) for cls in label_encoder.classes_]  # Dynamic class names from encoder\n",
    "plot_confusion_matrix(true_labels, predictions, class_names, f'confusion_matrix_{TARGET_VARIABLE}.png')\n",
    "plot_metrics_summary(true_labels, predictions, f'classification_metrics_{TARGET_VARIABLE}.png')\n",
    "\n",
    "# Save numerical metrics\n",
    "with open(f'test_metrics_{TARGET_VARIABLE}.txt', 'w') as f:\n",
    "    f.write(f\"Accuracy: {accuracy_score(true_labels, predictions):.4f}\\n\")\n",
    "    f.write(\"Classification Report:\\n\")\n",
    "    f.write(classification_report(true_labels, predictions, target_names=class_names))\n",
    "\n",
    "print(\"Evaluation completed. Saved:\")\n",
    "print(f\"- confusion_matrix{TARGET_VARIABLE}.png\")\n",
    "print(\"- classification_metrics{TARGET_VARIABLE}.png\")\n",
    "print(f\"- test_metrics.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
